{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "\n",
    "# importamos as libs\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula metricas de regressao\n",
    "def score_regression_metrics(y_test, y_test_pred):\n",
    "\n",
    "    RMSE = mean_squared_error(y_true=y_test, y_pred=y_test_pred, squared=False)\n",
    "    MAE = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    MAPE = mean_absolute_percentage_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    R2 = r2_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "    scores = {\n",
    "        \"neg_root_mean_squared_error\": RMSE,\n",
    "        \"neg_mean_absolute_error\": MAE,\n",
    "        \"neg_mean_absolute_percentage_error\": MAPE,\n",
    "    }\n",
    "\n",
    "    return scores\n",
    "\n",
    "def show_scores (scores):\n",
    "\n",
    "    print (\"Scores obtidos:\")\n",
    "\n",
    "    print (f\"RMSE: {scores['neg_root_mean_squared_error']}\")\n",
    "    print (f\"MAE: {scores['neg_mean_absolute_error']}\")\n",
    "    print (f\"MAPE: {scores['neg_mean_absolute_percentage_error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler3DShape:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_new = self.scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        return X_new\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_new = X.reshape(-1, X.shape[-1])\n",
    "        self.scaler.fit(X_new)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = self.scaler.transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds():\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input_and_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=47\n",
    "\n",
    "TO_DROP = [\n",
    "    \"pib_pc\",\n",
    "    \"idh_long\",\n",
    "    \"nfsp\",\n",
    "    \"estoque\",\n",
    "]\n",
    "\n",
    "VARS = [\n",
    "    'pib_pmc',\n",
    "    'pib_pcpt',\n",
    "    'populacao',\n",
    "    'pib_cc',\n",
    "    'ipca',\n",
    "    'incc',\n",
    "    'igp',\n",
    "    'selic',\n",
    "    'idh_renda',\n",
    "    'idh_educacao',\n",
    "    'desemprego'\n",
    "]\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "verbose = 1\n",
    "timesteps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO_DROP = [\n",
    "\n",
    "# ]\n",
    "\n",
    "# VARS = [\n",
    "#     \"pib_pc\",\n",
    "#     \"idh_long\",\n",
    "#     \"nfsp\",\n",
    "#     \"estoque\",\n",
    "#     'pib_pmc',\n",
    "#     'pib_pcpt',\n",
    "#     'populacao',\n",
    "#     'pib_cc',\n",
    "#     'ipca',\n",
    "#     'incc',\n",
    "#     'igp',\n",
    "#     'selic',\n",
    "#     'idh_renda',\n",
    "#     'idh_educacao',\n",
    "#     'desemprego'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(TO_DROP, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for var in VARS:\n",
    "#     df[var] = df[var].clip(upper=df[var].quantile(.75))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for var in VARS:\n",
    "#     df[var] = df[var].clip(upper=df[var].quantile(.75))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[VARS].hist(bins=25, figsize=(20, 20), layout=(-1, 5), edgecolor=\"black\")\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([\"data\", \"consumo\"], axis=1).copy()\n",
    "\n",
    "# processo de one-hot\n",
    "x = pd.get_dummies(data=x, columns=[\"estados\"], drop_first=True)\n",
    "\n",
    "# aqui só precisamos do valor do consumo em si \n",
    "y = df[[\"consumo\"]].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9040287172504055\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Score: {regr.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 728354.1570515295\n",
      "MAE: 459842.9989768059\n",
      "MAPE: 0.5743427085647832\n",
      "\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 729794.0032279178\n",
      "MAE: 464649.91215264314\n",
      "MAPE: 0.5904931776252598\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = regr.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "print()\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([\"data\", \"estados\", \"consumo\"], axis=1).copy()\n",
    "\n",
    "# aqui só precisamos do valor do consumo em si \n",
    "y = df[[\"consumo\"]].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.844156189958258\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Score: {regr.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 959893.0819658525\n",
      "MAE: 589453.8664613751\n",
      "MAPE: 1.1919070713848006\n",
      "\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 929981.7354214025\n",
      "MAE: 522448.1925750584\n",
      "MAPE: 0.6701396521781601\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = regr.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "print()\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    #model.add(tf.keras.layers.Dense(units=256, activation=\"relu\")),\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation=\"relu\")),\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "    model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"mse\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 3s 7ms/step - loss: 7916329893888.0000 - RMSE: 2813597.2500\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 7606600990720.0000 - RMSE: 2758006.7500\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5944956157952.0000 - RMSE: 2438228.0000\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3021212221440.0000 - RMSE: 1738163.5000\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1360166518784.0000 - RMSE: 1166261.7500\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 921011290112.0000 - RMSE: 959693.3125\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 772019978240.0000 - RMSE: 878646.6875TA: \n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 670445469696.0000 - RMSE: 818807.3750\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 542968086528.0000 - RMSE: 736863.6875\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 498242879488.0000 - RMSE: 705863.1875\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 478521753600.0000 - RMSE: 691752.6875\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 389989564416.0000 - RMSE: 624491.4375\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 386489909248.0000 - RMSE: 621683.1250\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 349234069504.0000 - RMSE: 590960.3125\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 334670823424.0000 - RMSE: 578507.4375\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 282407141376.0000 - RMSE: 531419.9375\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 250909310976.0000 - RMSE: 500908.5000\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 235589632000.0000 - RMSE: 485375.7500\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 223429132288.0000 - RMSE: 472682.9062\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 197331894272.0000 - RMSE: 444220.5625\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 172553601024.0000 - RMSE: 415395.7188\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 160270958592.0000 - RMSE: 400338.5625\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 150447439872.0000 - RMSE: 387875.5625\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 153020989440.0000 - RMSE: 391178.9688\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 135780556800.0000 - RMSE: 368484.1250\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 135541407744.0000 - RMSE: 368159.5000\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 122382573568.0000 - RMSE: 349832.2188\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 117679030272.0000 - RMSE: 343043.7812\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 113391296512.0000 - RMSE: 336736.2500\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 105155821568.0000 - RMSE: 324277.3750\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 114606227456.0000 - RMSE: 338535.4062\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 115518996480.0000 - RMSE: 339880.8438\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 101140013056.0000 - RMSE: 318025.1875\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 97264320512.0000 - RMSE: 311872.2812\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 92920070144.0000 - RMSE: 304827.9375\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 106352697344.0000 - RMSE: 326117.6250\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 89956319232.0000 - RMSE: 299927.1875\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 91410628608.0000 - RMSE: 302341.9062\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 108474785792.0000 - RMSE: 329355.0938\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 85241389056.0000 - RMSE: 291961.2812\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 83734659072.0000 - RMSE: 289369.4062\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 93177331712.0000 - RMSE: 305249.6250\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 84808228864.0000 - RMSE: 291218.5312\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 91045478400.0000 - RMSE: 301737.4375\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 85914329088.0000 - RMSE: 293111.4688\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 102664568832.0000 - RMSE: 320413.1250\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 80895213568.0000 - RMSE: 284420.8438\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 82075901952.0000 - RMSE: 286488.9062\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 87201685504.0000 - RMSE: 295299.3125\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 81485119488.0000 - RMSE: 285456.0000\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 82187337728.0000 - RMSE: 286683.3438\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 79470231552.0000 - RMSE: 281904.6562\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 86903840768.0000 - RMSE: 294794.5625\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 88346812416.0000 - RMSE: 297231.9062\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 96579534848.0000 - RMSE: 310772.4688\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 90218201088.0000 - RMSE: 300363.4375\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 90611523584.0000 - RMSE: 301017.4688\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 94132142080.0000 - RMSE: 306809.6250\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 83739459584.0000 - RMSE: 289377.7188\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 83410075648.0000 - RMSE: 288808.0312\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 101383315456.0000 - RMSE: 318407.4688\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 99067199488.0000 - RMSE: 314749.4375\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 82506629120.0000 - RMSE: 287239.6875\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 93441605632.0000 - RMSE: 305682.1875\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 85611741184.0000 - RMSE: 292594.8438\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 86347653120.0000 - RMSE: 293849.7188\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 87560781824.0000 - RMSE: 295906.718 - 2s 7ms/step - loss: 86317375488.0000 - RMSE: 293798.1875\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 91375984640.0000 - RMSE: 302284.5938\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 96700628992.0000 - RMSE: 310967.2500\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 84638515200.0000 - RMSE: 290927.0000\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 94260649984.0000 - RMSE: 307018.9688\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 86600957952.0000 - RMSE: 294280.4062\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 87764320256.0000 - RMSE: 296250.4375A: 1s - loss: 1024140\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 93119782912.0000 - RMSE: 305155.3438\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 90985914368.0000 - RMSE: 301638.7188\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 84109647872.0000 - RMSE: 290016.6250\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 83222618112.0000 - RMSE: 288483.3125\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 83444678656.0000 - RMSE: 288867.9375\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 91510890496.0000 - RMSE: 302507.6562\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 102732709888.0000 - RMSE: 320519.4375\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 77714710528.0000 - RMSE: 278773.5938\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 86075154432.0000 - RMSE: 293385.6875\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 89594961920.0000 - RMSE: 299324.1875\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 82640191488.0000 - RMSE: 287472.0625\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 91615199232.0000 - RMSE: 302680.0312\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 76728672256.0000 - RMSE: 276999.4062\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 91912790016.0000 - RMSE: 303171.2188A: 0s - loss: 92847849472.0000 - RMSE: 30470\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 92968755200.0000 - RMSE: 304907.7812\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 93161848832.0000 - RMSE: 305224.2500\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 80837001216.0000 - RMSE: 284318.5000A: 1s - loss: 633036922\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 91090558976.0000 - RMSE: 301812.1250\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 93980123136.0000 - RMSE: 306561.7812\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 88317526016.0000 - RMSE: 297182.6562\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 80683761664.0000 - RMSE: 284048.8750\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 81977155584.0000 - RMSE: 286316.5312\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 89657483264.0000 - RMSE: 299428.5938\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 87742849024.0000 - RMSE: 296214.1875\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 88485715968.0000 - RMSE: 297465.5000\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 94007754752.0000 - RMSE: 306606.8438\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 90632683520.0000 - RMSE: 301052.6250\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 85325217792.0000 - RMSE: 292104.8125\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 91278745600.0000 - RMSE: 302123.7188\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 78948081664.0000 - RMSE: 280977.0000\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 90523115520.0000 - RMSE: 300870.5938\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 80740818944.0000 - RMSE: 284149.2812\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 87232937984.0000 - RMSE: 295352.2188\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 88739692544.0000 - RMSE: 297892.0938\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 90400473088.0000 - RMSE: 300666.7188\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 84384104448.0000 - RMSE: 290489.4375\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 92106088448.0000 - RMSE: 303489.8438\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 81331052544.0000 - RMSE: 285186.0000\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 86864420864.0000 - RMSE: 294727.7188\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 82440290304.0000 - RMSE: 287124.1875\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 90372341760.0000 - RMSE: 300619.9375\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 86801481728.0000 - RMSE: 294620.9062\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 83752861696.0000 - RMSE: 289400.8750\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 98364801024.0000 - RMSE: 313631.6250\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 89279340544.0000 - RMSE: 298796.5000\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 81068851200.0000 - RMSE: 284725.9375\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 85125128192.0000 - RMSE: 291762.0938\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 84831920128.0000 - RMSE: 291259.1875\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 93881917440.0000 - RMSE: 306401.5625\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 94735106048.0000 - RMSE: 307790.6875\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 92539936768.0000 - RMSE: 304203.7812\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 90486423552.0000 - RMSE: 300809.6250\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 90057138176.0000 - RMSE: 300095.2188\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 91481833472.0000 - RMSE: 302459.6250\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 93842309120.0000 - RMSE: 306336.9062\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 88666062848.0000 - RMSE: 297768.4688\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 82270494720.0000 - RMSE: 286828.3438\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 93118144512.0000 - RMSE: 305152.6562\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 84665212928.0000 - RMSE: 290972.8750\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 89681567744.0000 - RMSE: 299468.8125\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 101362827264.0000 - RMSE: 318375.2812\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 80436396032.0000 - RMSE: 283613.1250\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 92224651264.0000 - RMSE: 303685.1250\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 92733554688.0000 - RMSE: 304521.8438\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 79351291904.0000 - RMSE: 281693.6250\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 81643003904.0000 - RMSE: 285732.4062\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 74897408000.0000 - RMSE: 273673.9062\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 92762824704.0000 - RMSE: 304569.9062\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 87984758784.0000 - RMSE: 296622.2500\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 83414106112.0000 - RMSE: 288815.0000\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 90492952576.0000 - RMSE: 300820.4688\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 91872837632.0000 - RMSE: 303105.3125\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 89030606848.0000 - RMSE: 298379.9688\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 92241133568.0000 - RMSE: 303712.2500\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 78001823744.0000 - RMSE: 279288.0625\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 81037787136.0000 - RMSE: 284671.3750\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 78818926592.0000 - RMSE: 280747.0938\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 84994490368.0000 - RMSE: 291538.1562\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 79002288128.0000 - RMSE: 281073.4688\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 87990992896.0000 - RMSE: 296632.7500\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 97511317504.0000 - RMSE: 312268.0312\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 85432754176.0000 - RMSE: 292288.8125\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 81836515328.0000 - RMSE: 286070.8125\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 84802658304.0000 - RMSE: 291208.9688\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 93322747904.0000 - RMSE: 305487.7188\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 88674762752.0000 - RMSE: 297783.0938\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 89122381824.0000 - RMSE: 298533.7188\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 91956428800.0000 - RMSE: 303243.1875\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 78514831360.0000 - RMSE: 280204.9688\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 80854204416.0000 - RMSE: 284348.7500\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 86371319808.0000 - RMSE: 293889.9688\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 87545872384.0000 - RMSE: 295881.5312\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 91884961792.0000 - RMSE: 303125.3125\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 85163098112.0000 - RMSE: 291827.1562\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 86199115776.0000 - RMSE: 293596.8438\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 86897401856.0000 - RMSE: 294783.6562\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 82190286848.0000 - RMSE: 286688.4688\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 87558545408.0000 - RMSE: 295902.9375\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 87060742144.0000 - RMSE: 295060.5625\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 85066547200.0000 - RMSE: 291661.6875\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 85758713856.0000 - RMSE: 292845.8750\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 82540519424.0000 - RMSE: 287298.6562\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 85623218176.0000 - RMSE: 292614.4375\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 81418240000.0000 - RMSE: 285338.8125\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 105133121536.0000 - RMSE: 324242.3750\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 84559511552.0000 - RMSE: 290791.1875\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 86673022976.0000 - RMSE: 294402.8125\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 94954430464.0000 - RMSE: 308146.7812\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 93968400384.0000 - RMSE: 306542.6562\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 91724439552.0000 - RMSE: 302860.4375\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 78073085952.0000 - RMSE: 279415.6250\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 92733186048.0000 - RMSE: 304521.2500\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 87204536320.0000 - RMSE: 295304.1562\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 80924762112.0000 - RMSE: 284472.7812\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 90411122688.0000 - RMSE: 300684.4375\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 90997481472.0000 - RMSE: 301657.8750\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 99860324352.0000 - RMSE: 316006.8438\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 79318310912.0000 - RMSE: 281635.0625\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 77934002176.0000 - RMSE: 279166.6250\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 87764992000.0000 - RMSE: 296251.5625\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 82976407552.0000 - RMSE: 288056.2500\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 93715783680.0000 - RMSE: 306130.3438\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 92864323584.0000 - RMSE: 304736.4688\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 95447703552.0000 - RMSE: 308946.1250\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 86998196224.0000 - RMSE: 294954.5625\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 96220069888.0000 - RMSE: 310193.5938\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 82252447744.0000 - RMSE: 286796.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe944964e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop([\"estados\", \"data\"], axis=1)\n",
    "y = df[\"consumo\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = get_model()\n",
    "set_seeds()\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 12576.403887420529\n",
      "MAE: 9357.830837144036\n",
      "MAPE: 0.02827587341015946\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 17529.11764329167\n",
      "MAE: 11708.51924058067\n",
      "MAPE: 0.0502694336291905\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 3s 5ms/step - loss: 7895401365504.0000 - RMSE: 2809875.7500\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 6905841844224.0000 - RMSE: 2627896.7500\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3050340876288.0000 - RMSE: 1746522.5000\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 818758352896.0000 - RMSE: 904852.6875\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 600752914432.0000 - RMSE: 775082.5000\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 548182917120.0000 - RMSE: 740393.7500\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 512521928704.0000 - RMSE: 715906.3750\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 469646180352.0000 - RMSE: 685307.3750\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 447186075648.0000 - RMSE: 668719.7500\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 424845246464.0000 - RMSE: 651801.5625\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 403532873728.0000 - RMSE: 635242.3750\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 395872501760.0000 - RMSE: 629184.0000\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 362267705344.0000 - RMSE: 601886.8125\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 336782524416.0000 - RMSE: 580329.6875\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 323206021120.0000 - RMSE: 568512.1250\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 289510621184.0000 - RMSE: 538061.9375\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 287316279296.0000 - RMSE: 536018.9375\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 273918361600.0000 - RMSE: 523372.0938\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 248518197248.0000 - RMSE: 498516.0000\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 233148760064.0000 - RMSE: 482854.8125\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 227832233984.0000 - RMSE: 477317.7500\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 207105802240.0000 - RMSE: 455088.7812\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 190654955520.0000 - RMSE: 436640.5312\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 185733218304.0000 - RMSE: 430967.7812\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 174797324288.0000 - RMSE: 418087.6875\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 153951174656.0000 - RMSE: 392366.1250\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 148696252416.0000 - RMSE: 385611.5312\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 138119331840.0000 - RMSE: 371644.0938\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 119038664704.0000 - RMSE: 345019.8125\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 118593708032.0000 - RMSE: 344374.3750\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 107835858944.0000 - RMSE: 328383.7188\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 97978753024.0000 - RMSE: 313015.5938\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 108734504960.0000 - RMSE: 329749.1562\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 104917712896.0000 - RMSE: 323910.0312: 0s - loss: 108180602880.0000 - RMSE:\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 89413902336.0000 - RMSE: 299021.5625A: 1s - loss: 819902464\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 80924811264.0000 - RMSE: 284472.8750\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 83656728576.0000 - RMSE: 289234.7188\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 79131869184.0000 - RMSE: 281303.8750\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 78661378048.0000 - RMSE: 280466.3438\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 84261675008.0000 - RMSE: 290278.6250\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 74200915968.0000 - RMSE: 272398.4375A: 2s - loss: 1010235\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 68791754752.0000 - RMSE: 262281.8125\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 76439003136.0000 - RMSE: 276476.0312\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 70235856896.0000 - RMSE: 265020.4688\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 73879216128.0000 - RMSE: 271807.3125\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 72911167488.0000 - RMSE: 270020.6875\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 70177382400.0000 - RMSE: 264910.1250\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 74802561024.0000 - RMSE: 273500.5625\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 69988106240.0000 - RMSE: 264552.6562\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 69605449728.0000 - RMSE: 263828.4375\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 70968066048.0000 - RMSE: 266398.3125\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 73983614976.0000 - RMSE: 271999.2812\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 68596768768.0000 - RMSE: 261909.8438\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 67057807360.0000 - RMSE: 258955.2188\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 72038391808.0000 - RMSE: 268399.6875\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 80560693248.0000 - RMSE: 283832.1562\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 69925822464.0000 - RMSE: 264434.9062\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 70667583488.0000 - RMSE: 265833.7500\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 70481117184.0000 - RMSE: 265482.8125\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 69249040384.0000 - RMSE: 263152.1250\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 63909580800.0000 - RMSE: 252803.4375\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 64009322496.0000 - RMSE: 253000.6406\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 71937720320.0000 - RMSE: 268212.0938\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 68777664512.0000 - RMSE: 262254.9688\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 62398369792.0000 - RMSE: 249796.6562\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64642224128.0000 - RMSE: 254248.3438\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 64436424704.0000 - RMSE: 253843.3125\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 63358476288.0000 - RMSE: 251711.0938\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 64851873792.0000 - RMSE: 254660.3125\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 67192082432.0000 - RMSE: 259214.3594\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 72043577344.0000 - RMSE: 268409.3438\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 68260900864.0000 - RMSE: 261267.8750\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 71282458624.0000 - RMSE: 266987.7500\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 67830288384.0000 - RMSE: 260442.4844\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66595753984.0000 - RMSE: 258061.5312\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 69138399232.0000 - RMSE: 262941.8125\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 67742998528.0000 - RMSE: 260274.8594\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 67289149440.0000 - RMSE: 259401.5156\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 68353003520.0000 - RMSE: 261444.0781\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 69526593536.0000 - RMSE: 263678.9688\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66560761856.0000 - RMSE: 257993.7188\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66943406080.0000 - RMSE: 258734.2344\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 72424497152.0000 - RMSE: 269118.0000\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 66012012544.0000 - RMSE: 256928.0312\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 68421668864.0000 - RMSE: 261575.3594\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 63701995520.0000 - RMSE: 252392.5469\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 65325260800.0000 - RMSE: 255588.0625\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 70250233856.0000 - RMSE: 265047.5938\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 68562702336.0000 - RMSE: 261844.8125\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 70228500480.0000 - RMSE: 265006.5938\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 69225381888.0000 - RMSE: 263107.1562\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 73112264704.0000 - RMSE: 270392.8125\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 67556417536.0000 - RMSE: 259916.1719\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64360402944.0000 - RMSE: 253693.5156\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 69567594496.0000 - RMSE: 263756.6875\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64114630656.0000 - RMSE: 253208.6719\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66442153984.0000 - RMSE: 257763.7500\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 69055062016.0000 - RMSE: 262783.3125\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66591145984.0000 - RMSE: 258052.6094\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 59498987520.0000 - RMSE: 243924.1406\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 62627155968.0000 - RMSE: 250254.1875\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 64307228672.0000 - RMSE: 253588.7031\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64896012288.0000 - RMSE: 254746.9531\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 70645719040.0000 - RMSE: 265792.6250\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 69840453632.0000 - RMSE: 264273.4375\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 67402526720.0000 - RMSE: 259619.9688\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 65293242368.0000 - RMSE: 255525.4219\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 69954420736.0000 - RMSE: 264488.9688\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 65781366784.0000 - RMSE: 256478.7812\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 68395782144.0000 - RMSE: 261525.8750\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 71462551552.0000 - RMSE: 267324.8125\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 62569537536.0000 - RMSE: 250139.0312\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66414252032.0000 - RMSE: 257709.6250\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 60528390144.0000 - RMSE: 246025.1875\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66342248448.0000 - RMSE: 257569.8906\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64371773440.0000 - RMSE: 253715.9375\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 66344157184.0000 - RMSE: 257573.5938\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 59454672896.0000 - RMSE: 243833.2969\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 61698097152.0000 - RMSE: 248391.0156\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 63544115200.0000 - RMSE: 252079.5781\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 71565590528.0000 - RMSE: 267517.4688\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64505450496.0000 - RMSE: 253979.2344\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 62783537152.0000 - RMSE: 250566.4375\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 65148837888.0000 - RMSE: 255242.7031\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 65317535744.0000 - RMSE: 255572.9531\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 64823046144.0000 - RMSE: 254603.7031\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 59499266048.0000 - RMSE: 243924.7188\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 61661335552.0000 - RMSE: 248317.0000\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 62201229312.0000 - RMSE: 249401.7500\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 64395182080.0000 - RMSE: 253762.0625\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 58328834048.0000 - RMSE: 241513.6250\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 68701261824.0000 - RMSE: 262109.2500\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 71639678976.0000 - RMSE: 267655.9062\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 61068746752.0000 - RMSE: 247120.9219\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 62953963520.0000 - RMSE: 250906.2812\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 58833584128.0000 - RMSE: 242556.3594\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64035573760.0000 - RMSE: 253052.5156\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 64235892736.0000 - RMSE: 253448.0156\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 66161332224.0000 - RMSE: 257218.4531\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 64209588224.0000 - RMSE: 253396.1094\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 58403332096.0000 - RMSE: 241667.8125\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 63084941312.0000 - RMSE: 251167.1562\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 65121964032.0000 - RMSE: 255190.0625\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 57857716224.0000 - RMSE: 240536.3125\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 65326149632.0000 - RMSE: 255589.8125\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 57803083776.0000 - RMSE: 240422.7188\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 56416002048.0000 - RMSE: 237520.5312\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 60424015872.0000 - RMSE: 245812.9688\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 63026675712.0000 - RMSE: 251051.1406\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 63362228224.0000 - RMSE: 251718.5469\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 60156141568.0000 - RMSE: 245267.4844\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 65487228928.0000 - RMSE: 255904.7188\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 61495136256.0000 - RMSE: 247982.1250\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 61290995712.0000 - RMSE: 247570.1875\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 55702781952.0000 - RMSE: 236014.3750\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 61541195776.0000 - RMSE: 248074.9844\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 64579846144.0000 - RMSE: 254125.6562\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 65037672448.0000 - RMSE: 255024.8438\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 57765236736.0000 - RMSE: 240344.0000\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 66582851584.0000 - RMSE: 258036.5312\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 63805792256.0000 - RMSE: 252598.0781\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 58700972032.0000 - RMSE: 242282.8281\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 55674130432.0000 - RMSE: 235953.6562\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 61138489344.0000 - RMSE: 247261.9844\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 60887363584.0000 - RMSE: 246753.6562\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 60058288128.0000 - RMSE: 245067.9219\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 57746628608.0000 - RMSE: 240305.2812\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 58446721024.0000 - RMSE: 241757.5625A: 1s - loss: 53998858240.\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 58987524096.0000 - RMSE: 242873.4688\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 62698176512.0000 - RMSE: 250396.0469\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 62054486016.0000 - RMSE: 249107.3750\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 54437408768.0000 - RMSE: 233318.2500\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 56227565568.0000 - RMSE: 237123.5312\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 56554496000.0000 - RMSE: 237811.8906\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 61089488896.0000 - RMSE: 247162.8750\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 62300409856.0000 - RMSE: 249600.5000\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 59074326528.0000 - RMSE: 243052.1094\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 56905965568.0000 - RMSE: 238549.7188\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 59819184128.0000 - RMSE: 244579.6094\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 59313733632.0000 - RMSE: 243544.1094\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 61308747776.0000 - RMSE: 247606.0312\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 57887174656.0000 - RMSE: 240597.5312\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 68617236480.0000 - RMSE: 261948.9219\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 54506229760.0000 - RMSE: 233465.6875\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 58151993344.0000 - RMSE: 241147.2500\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 55223504896.0000 - RMSE: 234996.8125\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 56402472960.0000 - RMSE: 237492.0469\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 54341238784.0000 - RMSE: 233112.0781\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 58148474880.0000 - RMSE: 241139.9531\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 55176101888.0000 - RMSE: 234895.9375\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 58278555648.0000 - RMSE: 241409.5156\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 55999320064.0000 - RMSE: 236641.7500\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 58882494464.0000 - RMSE: 242657.1562\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 51600826368.0000 - RMSE: 227158.1562\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 49896452096.0000 - RMSE: 223375.1406\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 53636829184.0000 - RMSE: 231596.2656\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 61648125952.0000 - RMSE: 248290.4062\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 56768147456.0000 - RMSE: 238260.6719\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 67428790272.0000 - RMSE: 259670.5469\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 57097162752.0000 - RMSE: 238950.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe947d1080>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = df.drop([\"estados\", \"data\"], axis=1)\n",
    "x = pd.get_dummies(data=df.drop([\"data\"], axis=1), columns=[\"estados\"], drop_first=True)\n",
    "y = df[\"consumo\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 70592.9345211642\n",
      "MAE: 47825.52684364173\n",
      "MAPE: 0.1773794592301615\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 74500.3454443094\n",
      "MAE: 54028.48803054077\n",
      "MAPE: 0.18284895261072728\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=32, activation=\"relu\", return_sequences=True)),\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D()),\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"mse\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 10s 16ms/step - loss: 7925261139968.0000 - RMSE: 2815184.0000\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 7904064700416.0000 - RMSE: 2811416.7500\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 7741244964864.0000 - RMSE: 2782309.2500\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 7281739563008.0000 - RMSE: 2698469.7500\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 6568524382208.0000 - RMSE: 2562913.2500\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 5942512451584.0000 - RMSE: 2437727.0000\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 5577732259840.0000 - RMSE: 2361722.2500\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5354188963840.0000 - RMSE: 2313912.0000\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 5237419016192.0000 - RMSE: 2288540.7500\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 5122404909056.0000 - RMSE: 2263273.0000\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 5039541714944.0000 - RMSE: 2244892.2500\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4974070726656.0000 - RMSE: 2230262.5000\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4910146912256.0000 - RMSE: 2215885.2500\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4869923536896.0000 - RMSE: 2206790.2500\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 4825118932992.0000 - RMSE: 2196615.2500\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 4796319268864.0000 - RMSE: 2190050.0000\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4764276883456.0000 - RMSE: 2182722.2500\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4743562264576.0000 - RMSE: 2177972.0000\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4691831291904.0000 - RMSE: 2166063.5000\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4662650470400.0000 - RMSE: 2159317.2500\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4656971382784.0000 - RMSE: 2158001.7500\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4635101233152.0000 - RMSE: 2152928.5000\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4592065052672.0000 - RMSE: 2142910.5000\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4558217543680.0000 - RMSE: 2134998.2500\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4555951570944.0000 - RMSE: 2134467.5000\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 4519289683968.0000 - RMSE: 2125862.0000\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4501923168256.0000 - RMSE: 2121773.5000\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4472144658432.0000 - RMSE: 2114744.5000\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 4455903789056.0000 - RMSE: 2110901.2500\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4444784689152.0000 - RMSE: 2108265.7500\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 4423383252992.0000 - RMSE: 2103184.0000\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 4395192549376.0000 - RMSE: 2096471.5000\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4386731589632.0000 - RMSE: 2094452.6250\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4376465506304.0000 - RMSE: 2092000.3750\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 4345409568768.0000 - RMSE: 2084564.6250\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 4355846569984.0000 - RMSE: 2087066.5000\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4333310050304.0000 - RMSE: 2081660.3750\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 4307918782464.0000 - RMSE: 2075552.6250\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 4279825858560.0000 - RMSE: 2068774.0000\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 4282893205504.0000 - RMSE: 2069515.2500\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4249011879936.0000 - RMSE: 2061313.1250\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4262542442496.0000 - RMSE: 2064592.5000\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 4253478027264.0000 - RMSE: 2062396.1250\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4214749396992.0000 - RMSE: 2052985.5000\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4203380473856.0000 - RMSE: 2050214.7500\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 4185518243840.0000 - RMSE: 2045853.8750\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4184312381440.0000 - RMSE: 2045559.1250\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4182388506624.0000 - RMSE: 2045088.8750\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 4172326633472.0000 - RMSE: 2042627.3750\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4148146733056.0000 - RMSE: 2036700.0000\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 4134814875648.0000 - RMSE: 2033424.3750\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4137406169088.0000 - RMSE: 2034061.5000\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4123915190272.0000 - RMSE: 2030742.5000\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 4094404853760.0000 - RMSE: 2023463.6250\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4097265631232.0000 - RMSE: 2024170.3750\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4088550916096.0000 - RMSE: 2022016.5000\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4092393947136.0000 - RMSE: 2022966.6250\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4050556813312.0000 - RMSE: 2012599.5000\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4038669631488.0000 - RMSE: 2009644.1250\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 4054345056256.0000 - RMSE: 2013540.3750\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 4007495204864.0000 - RMSE: 2001872.8750\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 4027184054272.0000 - RMSE: 2006784.5000\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 4008097873920.0000 - RMSE: 2002023.5000\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3980771196928.0000 - RMSE: 1995187.0000\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 3978879041536.0000 - RMSE: 1994712.7500\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3945953755136.0000 - RMSE: 1986442.5000\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3948038062080.0000 - RMSE: 1986967.0000\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3927405232128.0000 - RMSE: 1981768.2500\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3885840203776.0000 - RMSE: 1971253.5000\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3868882108416.0000 - RMSE: 1966947.3750\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 3839632080896.0000 - RMSE: 1959497.8750\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 3828462911488.0000 - RMSE: 1956645.8750\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3818026696704.0000 - RMSE: 1953977.1250\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3798568534016.0000 - RMSE: 1948991.6250\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 3789138952192.0000 - RMSE: 1946571.1250\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3769597427712.0000 - RMSE: 1941545.1250\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3781485395968.0000 - RMSE: 1944604.1250\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3747186212864.0000 - RMSE: 1935765.0000\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3698809372672.0000 - RMSE: 1923228.8750\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3727902375936.0000 - RMSE: 1930777.6250 1s - loss:\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 3706577223680.0000 - RMSE: 1925247.3750\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 3703812390912.0000 - RMSE: 1924529.1250\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 3685801263104.0000 - RMSE: 1919844.1250\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3643370635264.0000 - RMSE: 1908761.5000\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 3648557154304.0000 - RMSE: 1910119.6250\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3617775157248.0000 - RMSE: 1902045.0000\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3620010721280.0000 - RMSE: 1902632.6250\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3617672658944.0000 - RMSE: 1902018.0000\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3596183142400.0000 - RMSE: 1896360.5000\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 3588879810560.0000 - RMSE: 1894433.8750\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3580124725248.0000 - RMSE: 1892121.7500\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3544894406656.0000 - RMSE: 1882789.0000\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3549642620928.0000 - RMSE: 1884049.5000\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3537203101696.0000 - RMSE: 1880745.3750\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3540060209152.0000 - RMSE: 1881504.7500\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3516916039680.0000 - RMSE: 1875344.2500\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 3500322324480.0000 - RMSE: 1870914.8750\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3462614482944.0000 - RMSE: 1860810.1250 1s -\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3453208756224.0000 - RMSE: 1858281.1250\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3431425376256.0000 - RMSE: 1852410.7500\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3428538122240.0000 - RMSE: 1851631.2500\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3444384464896.0000 - RMSE: 1855905.2500\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3410299191296.0000 - RMSE: 1846699.5000\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 3403285266432.0000 - RMSE: 1844799.5000\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 3421932617728.0000 - RMSE: 1849846.6250\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3376202645504.0000 - RMSE: 1837444.6250\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3393348435968.0000 - RMSE: 1842104.3750\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3389241950208.0000 - RMSE: 1840989.3750\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3363365978112.0000 - RMSE: 1833948.2500\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3364435263488.0000 - RMSE: 1834239.7500\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3352053940224.0000 - RMSE: 1830861.5000\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3350091792384.0000 - RMSE: 1830325.6250\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3317693677568.0000 - RMSE: 1821453.7500\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 3299798679552.0000 - RMSE: 1816534.7500\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3297747140608.0000 - RMSE: 1815970.0000\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3291919155200.0000 - RMSE: 1814364.6250\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3286557523968.0000 - RMSE: 1812886.5000\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3278355038208.0000 - RMSE: 1810622.8750\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3270567526400.0000 - RMSE: 1808471.0000\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 3255666212864.0000 - RMSE: 1804346.5000\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3247043248128.0000 - RMSE: 1801955.3750\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3244901269504.0000 - RMSE: 1801361.0000\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3201943994368.0000 - RMSE: 1789397.6250\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3165186162688.0000 - RMSE: 1779097.0000\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 3168863518720.0000 - RMSE: 1780130.2500\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 3176872280064.0000 - RMSE: 1782378.2500\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3139543498752.0000 - RMSE: 1771875.7500\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3134197858304.0000 - RMSE: 1770366.6250\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3118571716608.0000 - RMSE: 1765947.8750\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 3100873588736.0000 - RMSE: 1760929.7500\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3095776985088.0000 - RMSE: 1759482.0000\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3064228478976.0000 - RMSE: 1750493.7500\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3091219611648.0000 - RMSE: 1758186.5000\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 3084877037568.0000 - RMSE: 1756381.7500\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3095973068800.0000 - RMSE: 1759537.7500\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3021075906560.0000 - RMSE: 1738124.2500\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3023124299776.0000 - RMSE: 1738713.3750\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 3061404401664.0000 - RMSE: 1749687.0000\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3044841095168.0000 - RMSE: 1744947.2500\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3012287528960.0000 - RMSE: 1735594.2500\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 3012644831232.0000 - RMSE: 1735697.2500\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 2993913856000.0000 - RMSE: 1730293.0000\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2979573530624.0000 - RMSE: 1726144.1250\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2987355537408.0000 - RMSE: 1728396.7500\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2982108463104.0000 - RMSE: 1726878.2500\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2993449074688.0000 - RMSE: 1730158.6250\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2977898430464.0000 - RMSE: 1725658.8750\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2965510291456.0000 - RMSE: 1722065.7500\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2964615593984.0000 - RMSE: 1721805.8750\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2961648123904.0000 - RMSE: 1720944.0000\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3034465697792.0000 - RMSE: 1741971.7500\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2989227245568.0000 - RMSE: 1728938.1250\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3020873793536.0000 - RMSE: 1738066.1250\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3004632137728.0000 - RMSE: 1733387.5000\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3016733491200.0000 - RMSE: 1736874.6250\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2983889469440.0000 - RMSE: 1727393.8750\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 3009190821888.0000 - RMSE: 1734702.0000\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2973754982400.0000 - RMSE: 1724457.8750\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2966547857408.0000 - RMSE: 1722366.8750\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2914882682880.0000 - RMSE: 1707302.7500\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2945510277120.0000 - RMSE: 1716248.8750\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2938993901568.0000 - RMSE: 1714349.3750\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2939775614976.0000 - RMSE: 1714577.3750\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2917003952128.0000 - RMSE: 1707923.8750\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2941249126400.0000 - RMSE: 1715007.0000\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2974957436928.0000 - RMSE: 1724806.5000\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2922600464384.0000 - RMSE: 1709561.5000\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2883914039296.0000 - RMSE: 1698209.1250\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2889194668032.0000 - RMSE: 1699763.1250\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2902555361280.0000 - RMSE: 1703688.7500\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2908442591232.0000 - RMSE: 1705415.6250\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2898259607552.0000 - RMSE: 1702427.6250\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2882816704512.0000 - RMSE: 1697886.0000\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2918253330432.0000 - RMSE: 1708289.6250\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2870557540352.0000 - RMSE: 1694272.0000\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2863980609536.0000 - RMSE: 1692329.8750\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2850952839168.0000 - RMSE: 1688476.5000\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2838542942208.0000 - RMSE: 1684797.6250\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 2859453644800.0000 - RMSE: 1690991.8750\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 2873927139328.0000 - RMSE: 1695266.1250\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 2860524240896.0000 - RMSE: 1691308.5000\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2824688631808.0000 - RMSE: 1680681.0000\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2807759896576.0000 - RMSE: 1675637.1250\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2828692881408.0000 - RMSE: 1681871.8750\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 2806325182464.0000 - RMSE: 1675209.0000\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 2817940258816.0000 - RMSE: 1678672.1250\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2794904879104.0000 - RMSE: 1671796.8750\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2801510907904.0000 - RMSE: 1673771.5000\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2811455602688.0000 - RMSE: 1676739.6250\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2815771017216.0000 - RMSE: 1678025.8750\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2787364044800.0000 - RMSE: 1669540.1250\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2762167025664.0000 - RMSE: 1661976.8750\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 2808988303360.0000 - RMSE: 1676003.6250\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 2770516574208.0000 - RMSE: 1664486.8750\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2746723074048.0000 - RMSE: 1657324.1250\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 2738985631744.0000 - RMSE: 1654988.1250\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2757963284480.0000 - RMSE: 1660711.6250\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2742357590016.0000 - RMSE: 1656006.5000\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2745880543232.0000 - RMSE: 1657069.8750\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 2738040864768.0000 - RMSE: 1654702.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbea22c85f8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = split_sequences(df.drop([\"estados\", \"data\"], axis=1).values, timesteps)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)\n",
    "scaler = StandardScaler3DShape()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 1643531.8119198007\n",
      "MAE: 961708.9786198909\n",
      "MAPE: 3.218955152249913\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 1856253.1239655064\n",
      "MAE: 1025329.4853855793\n",
      "MAPE: 3.2773748794606314\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=128, activation=\"relu\", return_sequences=True)),\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D()),\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.10))\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation=\"relu\")),\n",
    "    model.add(tf.keras.layers.Dense(units=32, activation=\"relu\")),\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"mse\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 11s 20ms/step - loss: 7178841227264.0000 - RMSE: 2679336.0000\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 5093834358784.0000 - RMSE: 2256952.5000\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 4868188667904.0000 - RMSE: 2206397.2500\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 4804660690944.0000 - RMSE: 2191953.5000 1s - loss:\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 4740293853184.0000 - RMSE: 2177221.5000\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 4695315709952.0000 - RMSE: 2166867.7500\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 4628081016832.0000 - RMSE: 2151297.5000\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 4587365335040.0000 - RMSE: 2141813.5000\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 4517915525120.0000 - RMSE: 2125539.0000\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 4453011816448.0000 - RMSE: 2110216.0000\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 4403210223616.0000 - RMSE: 2098382.7500\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 4304306700288.0000 - RMSE: 2074682.3750\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 4165279154176.0000 - RMSE: 2040901.5000\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 3965096558592.0000 - RMSE: 1991255.0000\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3812879499264.0000 - RMSE: 1952659.6250\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3660395839488.0000 - RMSE: 1913216.1250\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 3405275201536.0000 - RMSE: 1845338.7500\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3191402397696.0000 - RMSE: 1786449.6250\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 3073778647040.0000 - RMSE: 1753219.5000\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 2908078211072.0000 - RMSE: 1705308.8750\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 2748634628096.0000 - RMSE: 1657900.6250\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 2652619931648.0000 - RMSE: 1628686.6250\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 2402752135168.0000 - RMSE: 1550081.3750\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 2437523177472.0000 - RMSE: 1561256.8750\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 2199920836608.0000 - RMSE: 1483213.0000\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1855892488192.0000 - RMSE: 1362311.5000\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1800525971456.0000 - RMSE: 1341836.7500\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1775121989632.0000 - RMSE: 1332337.0000\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1538933784576.0000 - RMSE: 1240537.7500\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1567822315520.0000 - RMSE: 1252127.1250\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1932692684800.0000 - RMSE: 1390213.1250\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1543646347264.0000 - RMSE: 1242435.6250\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1597556916224.0000 - RMSE: 1263945.0000\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1665397686272.0000 - RMSE: 1290502.8750\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1428082524160.0000 - RMSE: 1195024.1250\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1204015857664.0000 - RMSE: 1097276.6250\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1068587286528.0000 - RMSE: 1033724.9375\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1020196028416.0000 - RMSE: 1010047.5625\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1032973975552.0000 - RMSE: 1016353.2500\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1153882390528.0000 - RMSE: 1074189.1250\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 980378189824.0000 - RMSE: 990140.5000\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 946072584192.0000 - RMSE: 972662.6250\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 954351747072.0000 - RMSE: 976909.3125\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 810520543232.0000 - RMSE: 900289.1250\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 740755374080.0000 - RMSE: 860671.4375\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 857259180032.0000 - RMSE: 925882.9375\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 704939098112.0000 - RMSE: 839606.5000\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 763218362368.0000 - RMSE: 873623.6875\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 1093432246272.0000 - RMSE: 1045673.1250 ETA: 2s - loss: 1056102678528.0000 - RM - - ETA: 0s - loss: 1097743204352.0000 -  - 7s 27ms/step - loss: 1093432246272.0000 - RMSE: 1045673.1250\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 960896565248.0000 - RMSE: 980253.3125 0s - loss: 958687084544.0000 - RMSE: 9\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 703304499200.0000 - RMSE: 838632.5000\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 658335465472.0000 - RMSE: 811378.7500\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 686768521216.0000 - RMSE: 828715.0000\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 724239581184.0000 - RMSE: 851022.6875\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 664312872960.0000 - RMSE: 815053.9375\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 759892279296.0000 - RMSE: 871718.0000\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 827481391104.0000 - RMSE: 909660.0625 0s - loss: 841946693632.0000 - RMS\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 632674123776.0000 - RMSE: 795408.1250\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 605969383424.0000 - RMSE: 778440.3750\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 693213396992.0000 - RMSE: 832594.3750\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 593973149696.0000 - RMSE: 770696.5625 \n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 611899146240.0000 - RMSE: 782239.8125\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 624915841024.0000 - RMSE: 790516.1875\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 721965744128.0000 - RMSE: 849685.6875\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 757582659584.0000 - RMSE: 870392.2500\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 596164345856.0000 - RMSE: 772116.8125\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 590756904960.0000 - RMSE: 768607.1250\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 660740505600.0000 - RMSE: 812859.4375\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 599258759168.0000 - RMSE: 774118.0625\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 530692931584.0000 - RMSE: 728486.7500\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 535622877184.0000 - RMSE: 731862.6250 1s - loss: 527217295360. - ETA: 0s - loss: 53077170585\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 547534471168.0000 - RMSE: 739955.7500\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 536796528640.0000 - RMSE: 732664.0000\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 501517877248.0000 - RMSE: 708179.2500\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 522024681472.0000 - RMSE: 722512.7500\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 527421308928.0000 - RMSE: 726237.7500\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 539801976832.0000 - RMSE: 734712.1875\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 489124790272.0000 - RMSE: 699374.5625\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 485913198592.0000 - RMSE: 697074.7500 2s - loss: 488 - ETA: 0s - loss: 490282549248.0000 - RMS - ETA: 0s - loss: 489201401856.0000\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 529245929472.0000 - RMSE: 727492.9375\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 526116519936.0000 - RMSE: 725338.8750\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 513674510336.0000 - RMSE: 716710.8750\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 477931700224.0000 - RMSE: 691326.0625\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 496928260096.0000 - RMSE: 704931.3750\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 498941591552.0000 - RMSE: 706358.0000\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 489788669952.0000 - RMSE: 699849.0625\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 493808549888.0000 - RMSE: 702715.1250\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 615645511680.0000 - RMSE: 784630.8125\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 490863656960.0000 - RMSE: 700616.6250\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 558747746304.0000 - RMSE: 747494.3125\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 509296672768.0000 - RMSE: 713650.2500\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 450856681472.0000 - RMSE: 671458.6250\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 468031569920.0000 - RMSE: 684128.3125\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 489646784512.0000 - RMSE: 699747.6875\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 444830973952.0000 - RMSE: 666956.5000\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 453175902208.0000 - RMSE: 673183.4375\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 458696261632.0000 - RMSE: 677271.1875\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 553597075456.0000 - RMSE: 744041.0625\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 471917985792.0000 - RMSE: 686962.8750\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 457275441152.0000 - RMSE: 676221.4375\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 458559750144.0000 - RMSE: 677170.3750 0s - loss: 459266293760.0000 - RMSE: 677691.\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 432841949184.0000 - RMSE: 657907.2500\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 445167271936.0000 - RMSE: 667208.5625\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 427701370880.0000 - RMSE: 653988.8125\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 384693796864.0000 - RMSE: 620236.8750\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 393868836864.0000 - RMSE: 627589.6875\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 422112133120.0000 - RMSE: 649701.5625\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 422924419072.0000 - RMSE: 650326.3750\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 447241879552.0000 - RMSE: 668761.4375\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 401962663936.0000 - RMSE: 634005.2500\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 393673211904.0000 - RMSE: 627433.8125\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 379670855680.0000 - RMSE: 616174.3750\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 374155476992.0000 - RMSE: 611682.5000\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 380005580800.0000 - RMSE: 616445.9375\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 388229005312.0000 - RMSE: 623080.2500\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 375511580672.0000 - RMSE: 612790.0000\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 388730421248.0000 - RMSE: 623482.5000\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 371280379904.0000 - RMSE: 609327.8125\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 378869121024.0000 - RMSE: 615523.4375\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 413441720320.0000 - RMSE: 642994.3125\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 364270190592.0000 - RMSE: 603548.0000\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 359595835392.0000 - RMSE: 599663.1250\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 373707046912.0000 - RMSE: 611315.8125\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 349519478784.0000 - RMSE: 591201.7500\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 348702408704.0000 - RMSE: 590510.3125 0s - loss: 357248663552.0000 - RMSE: - ETA: 0s - loss: 3550374\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 357099634688.0000 - RMSE: 597578.12 - 7s 28ms/step - loss: 357099634688.0000 - RMSE: 597578.1250\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 363854528512.0000 - RMSE: 603203.5625\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 376386912256.0000 - RMSE: 613503.8125\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 334025916416.0000 - RMSE: 577949.7500\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 354681356288.0000 - RMSE: 595551.3125\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 326721306624.0000 - RMSE: 571595.3750\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 357742739456.0000 - RMSE: 598116.0000\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 348418408448.0000 - RMSE: 590269.7500\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 345060737024.0000 - RMSE: 587418.6875\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 333612417024.0000 - RMSE: 577591.9375A: 2s - loss: 326811353088. - ETA: 1s - loss: - ETA: 0s - loss: 334122156032.0000 - R\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 347829043200.0000 - RMSE: 589770.3125\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 362673569792.0000 - RMSE: 602223.8750 1s -\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 347387756544.0000 - RMSE: 589396.1250\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 333834452992.0000 - RMSE: 577784.0625\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 325205000192.0000 - RMSE: 570267.5000 0s - loss: 317295886336.0000 - RMSE: 563 - ETA: 0s - loss: 324270555136.0000 - RMSE: 56944\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 331723997184.0000 - RMSE: 575954.8750\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 321970044928.0000 - RMSE: 567424.0625\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 336766173184.0000 - RMSE: 580315.5625\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 325836603392.0000 - RMSE: 570821.0000\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 330344923136.0000 - RMSE: 574756.3750\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 322435776512.0000 - RMSE: 567834.3125\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 319655084032.0000 - RMSE: 565380.5000 \n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 326643875840.0000 - RMSE: 571527.6875\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 330688430080.0000 - RMSE: 575055.1250\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 313939066880.0000 - RMSE: 560302.6875 1s - ETA: 0s - loss: 320598278144.0000 - RMSE:\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 313482969088.0000 - RMSE: 559895.5000\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 315378008064.0000 - RMSE: 561585.2500 1s - loss: 310310600704.0000 - RMS - ETA: 0s - loss: 31592982118\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 300878331904.0000 - RMSE: 548523.7500\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 314980302848.0000 - RMSE: 561231.0625 2s - loss:\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 299578097664.0000 - RMSE: 547337.2500\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 297699147776.0000 - RMSE: 545618.1250\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 299964956672.0000 - RMSE: 547690.5625 0s - loss: 300745228288.00\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 299873632256.0000 - RMSE: 547607.1875\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 315943878656.0000 - RMSE: 562088.8750\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 321933082624.0000 - RMSE: 567391.5000\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 287327518720.0000 - RMSE: 536029.3750\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 290172960768.0000 - RMSE: 538677.0625\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 285305143296.0000 - RMSE: 534139.6250\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 295891959808.0000 - RMSE: 543959.5000\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 276835368960.0000 - RMSE: 526151.5000\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 279122477056.0000 - RMSE: 528320.4375\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 280506761216.0000 - RMSE: 529628.8750\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 280087330816.0000 - RMSE: 529232.7500\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 276934164480.0000 - RMSE: 526245.3750\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 276057587712.0000 - RMSE: 525411.8125\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 271579512832.0000 - RMSE: 521132.9062\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 267061477376.0000 - RMSE: 516779.9062\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 275459506176.0000 - RMSE: 524842.3750\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 287149981696.0000 - RMSE: 535863.7500\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 292404527104.0000 - RMSE: 540744.4375\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 314561331200.0000 - RMSE: 560857.6875\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 279363813376.0000 - RMSE: 528548.7500\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 279151837184.0000 - RMSE: 528348.1875\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 293837897728.0000 - RMSE: 542068.1875\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 266580131840.0000 - RMSE: 516314.0000\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 270656323584.0000 - RMSE: 520246.4062\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 282582843392.0000 - RMSE: 531585.1875\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 297404268544.0000 - RMSE: 545347.8125\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 314153041920.0000 - RMSE: 560493.56 - 5s 21ms/step - loss: 316986097664.0000 - RMSE: 563015.1875\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 297474097152.0000 - RMSE: 545411.8750\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 262844022784.0000 - RMSE: 512683.1562\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 248049369088.0000 - RMSE: 498045.5625\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 258581151744.0000 - RMSE: 508508.75 - 6s 23ms/step - loss: 258581151744.0000 - RMSE: 508508.7500\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 277424668672.0000 - RMSE: 526711.1875\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 278794698752.0000 - RMSE: 528010.1250\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 268919947264.0000 - RMSE: 518574.9062\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 267460657152.0000 - RMSE: 517166.0000\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 248387452928.0000 - RMSE: 498384.8438\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 270619705344.0000 - RMSE: 520211.2188\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 271650111488.0000 - RMSE: 521200.6562\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 271325855744.0000 - RMSE: 520889.5000\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 265766600704.0000 - RMSE: 515525.5625\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 292122066944.0000 - RMSE: 540483.1875\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 277964357632.0000 - RMSE: 527223.2500\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 258613772288.0000 - RMSE: 508540.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe844f9ef0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = split_sequences(df.drop([\"estados\", \"data\"], axis=1).values, timesteps)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)\n",
    "scaler = StandardScaler3DShape()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 443929.12511484534\n",
      "MAE: 282512.7996313748\n",
      "MAPE: 0.5220022297861832\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 977980.0045355747\n",
      "MAE: 506618.1719305113\n",
      "MAPE: 0.8634618847441115\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 19s 40ms/step - loss: 5856031145984.0000 - RMSE: 2419923.7500\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 4833391149056.0000 - RMSE: 2198497.5000\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 4689267523584.0000 - RMSE: 2165471.7500\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 4556190121984.0000 - RMSE: 2134523.5000\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 4405464662016.0000 - RMSE: 2098920.0000\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 4000290701312.0000 - RMSE: 2000072.6250\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 3609022955520.0000 - RMSE: 1899742.8750\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 3045112676352.0000 - RMSE: 1745025.1250\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 2517468184576.0000 - RMSE: 1586653.1250\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 2767374778368.0000 - RMSE: 1663542.8750\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 2759502331904.0000 - RMSE: 1661175.0000\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 2400938885120.0000 - RMSE: 1549496.3750\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 2296810307584.0000 - RMSE: 1515523.1250\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 2022345670656.0000 - RMSE: 1422092.0000\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 1935621881856.0000 - RMSE: 1391266.2500\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 1768484110336.0000 - RMSE: 1329843.6250\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1633296318464.0000 - RMSE: 1278004.8750\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 1540374921216.0000 - RMSE: 1241118.3750\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 1434873233408.0000 - RMSE: 1197862.0000\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 1362795036672.0000 - RMSE: 1167388.1250\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 1240494243840.0000 - RMSE: 1113774.7500\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 1254563905536.0000 - RMSE: 1120073.1250\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 1233055514624.0000 - RMSE: 1110430.3750\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 1120028065792.0000 - RMSE: 1058313.7500\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1078226583552.0000 - RMSE: 1038376.8750\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 902768164864.0000 - RMSE: 950141.1250\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 8s 30ms/step - loss: 864331956224.0000 - RMSE: 929694.5625\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 962298576896.0000 - RMSE: 980968.1875\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 1215027871744.0000 - RMSE: 1102283.0000\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 1009095016448.0000 - RMSE: 1004537.1875\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 1093153849344.0000 - RMSE: 1045540.0000\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 991056756736.0000 - RMSE: 995518.3125\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 799640715264.0000 - RMSE: 894226.3125\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 726410002432.0000 - RMSE: 852296.8750\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 945190928384.0000 - RMSE: 972209.3125\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 817929453568.0000 - RMSE: 904394.5000\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 674716581888.0000 - RMSE: 821411.3125\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 674191507456.0000 - RMSE: 821091.6250\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 739097378816.0000 - RMSE: 859707.7500\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 761172066304.0000 - RMSE: 872451.7500\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 601663930368.0000 - RMSE: 775670.0000\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 565219426304.0000 - RMSE: 751810.7500\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 560919740416.0000 - RMSE: 748945.7500\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 631337910272.0000 - RMSE: 794567.7500\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 552105082880.0000 - RMSE: 743037.7500\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 520142290944.0000 - RMSE: 721208.9375\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 667621326848.0000 - RMSE: 817081.0000\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 648254455808.0000 - RMSE: 805142.5000\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 6s 26ms/step - loss: 536935792640.0000 - RMSE: 732759.0000\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 482270511104.0000 - RMSE: 694457.0000\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 456003420160.0000 - RMSE: 675280.2500\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 462222786560.0000 - RMSE: 679869.6875\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 686561951744.0000 - RMSE: 828590.3125\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 785353474048.0000 - RMSE: 886201.6875\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 636761473024.0000 - RMSE: 797973.3750\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 571006320640.0000 - RMSE: 755649.6250\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 535991681024.0000 - RMSE: 732114.5000\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 494867415040.0000 - RMSE: 703468.1250\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 500118421504.0000 - RMSE: 707190.5000\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 438384328704.0000 - RMSE: 662106.0000\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 410657292288.0000 - RMSE: 640825.5000\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 540815065088.0000 - RMSE: 735401.3125\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 6s 26ms/step - loss: 545092075520.0000 - RMSE: 738303.5000\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 480976928768.0000 - RMSE: 693525.0000\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 520482422784.0000 - RMSE: 721444.6875\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 531635306496.0000 - RMSE: 729133.2500\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 434976423936.0000 - RMSE: 659527.4375\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 409818693632.0000 - RMSE: 640170.8125\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 409888161792.0000 - RMSE: 640225.0625 1s - loss: 4\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 378778877952.0000 - RMSE: 615450.1250\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 376260722688.0000 - RMSE: 613400.9375\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 391416905728.0000 - RMSE: 625633.1875\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 402817515520.0000 - RMSE: 634679.0625\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 469545713664.0000 - RMSE: 685234.0625\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 432996188160.0000 - RMSE: 658024.4375\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 409485508608.0000 - RMSE: 639910.5625\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 389902270464.0000 - RMSE: 624421.5625\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 519579467776.0000 - RMSE: 720818.6250\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 489883533312.0000 - RMSE: 699916.8125\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 374361948160.0000 - RMSE: 611851.2500\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 383751127040.0000 - RMSE: 619476.5000\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 433171464192.0000 - RMSE: 658157.6250\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 397734051840.0000 - RMSE: 630661.6250\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 365366116352.0000 - RMSE: 604455.2500\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 358404620288.0000 - RMSE: 598669.0625\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 375655563264.0000 - RMSE: 612907.4375\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 395473846272.0000 - RMSE: 628867.1250 0s - loss: 384121864192.0000\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 422325518336.0000 - RMSE: 649865.7500\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 370075435008.0000 - RMSE: 608338.2500\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 360107474944.0000 - RMSE: 600089.5625\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 338764333056.0000 - RMSE: 582034.6250\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 330361208832.0000 - RMSE: 574770.5625\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 375598317568.0000 - RMSE: 612860.7500 1s - loss:\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 407309320192.0000 - RMSE: 638207.8750\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 434182684672.0000 - RMSE: 658925.3750\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 360521498624.0000 - RMSE: 600434.4375\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 351186059264.0000 - RMSE: 592609.5625\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 379868282880.0000 - RMSE: 616334.5625\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 364445433856.0000 - RMSE: 603693.1875\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 311235346432.0000 - RMSE: 557884.6875 1s - loss: 31349\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 389159256064.0000 - RMSE: 623826.3125\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 415021989888.0000 - RMSE: 644222.0000\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 336074276864.0000 - RMSE: 579719.1250\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 317436755968.0000 - RMSE: 563415.2500\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 294679740416.0000 - RMSE: 542844.1250\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 303520088064.0000 - RMSE: 550926.5625\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 287147917312.0000 - RMSE: 535861.8750\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 274792644608.0000 - RMSE: 524206.6875\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 276820656128.0000 - RMSE: 526137.5000\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 292215554048.0000 - RMSE: 540569.6875\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 284963405824.0000 - RMSE: 533819.6250\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 279976935424.0000 - RMSE: 529128.4375\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 289395277824.0000 - RMSE: 537954.6875\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 277781446656.0000 - RMSE: 527049.7500\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 287168069632.0000 - RMSE: 535880.6250\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 313439813632.0000 - RMSE: 559856.9375\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 284212461568.0000 - RMSE: 533115.8125\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 299393056768.0000 - RMSE: 547168.1875\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 303222587392.0000 - RMSE: 550656.5000\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 297144221696.0000 - RMSE: 545109.3750\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 296656404480.0000 - RMSE: 544661.7500\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 284331933696.0000 - RMSE: 533227.8750\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 286359158784.0000 - RMSE: 535125.3750\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 260990976000.0000 - RMSE: 510872.7500\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 264266727424.0000 - RMSE: 514068.7812\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 283497758720.0000 - RMSE: 532445.0625\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 306140151808.0000 - RMSE: 553299.3125\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 262573228032.0000 - RMSE: 512419.0000\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 275605979136.0000 - RMSE: 524981.8750 0s - loss: 275346227200.0000 - RMSE: 52473\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 284541747200.0000 - RMSE: 533424.5625\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 277203353600.0000 - RMSE: 526501.0625\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 244037074944.0000 - RMSE: 494001.0938\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 270056030208.0000 - RMSE: 519669.1562\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 269779075072.0000 - RMSE: 519402.6250 1s -\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 244311900160.0000 - RMSE: 494279.1875\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 832357662720.0000 - RMSE: 912336.3750\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 599313874944.0000 - RMSE: 774153.6250\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 606888001536.0000 - RMSE: 779030.1875\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 445767057408.0000 - RMSE: 667657.8750\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 415943852032.0000 - RMSE: 644937.0625\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 437452963840.0000 - RMSE: 661402.2500\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 438384951296.0000 - RMSE: 662106.4375\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 1150652514304.0000 - RMSE: 1072684.7500\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 739390586880.0000 - RMSE: 859878.2500\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 452000415744.0000 - RMSE: 672309.7500\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 402452250624.0000 - RMSE: 634391.2500\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 357971197952.0000 - RMSE: 598306.9375\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 340646166528.0000 - RMSE: 583649.0000\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 363969282048.0000 - RMSE: 603298.6875\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 310742941696.0000 - RMSE: 557443.1875\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 297801515008.0000 - RMSE: 545711.9375\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 277664006144.0000 - RMSE: 526938.3125\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 268026003456.0000 - RMSE: 517712.2812\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 290704752640.0000 - RMSE: 539170.4375\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 283000930304.0000 - RMSE: 531978.3125\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 333758529536.0000 - RMSE: 577718.3750 1s - loss: 335\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 278764650496.0000 - RMSE: 527981.6875\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 299947425792.0000 - RMSE: 547674.5625\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 264279506944.0000 - RMSE: 514081.21 - 8s 31ms/step - loss: 265941876736.0000 - RMSE: 515695.5312\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 282735935488.0000 - RMSE: 531729.1875\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 414684610560.0000 - RMSE: 643960.1250 0s - loss: 4104162\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 328483569664.0000 - RMSE: 573134.8750\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 329231990784.0000 - RMSE: 573787.4375\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 335651045376.0000 - RMSE: 579354.0000\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 296654438400.0000 - RMSE: 544659.9375\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 270007615488.0000 - RMSE: 519622.5625\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 274305122304.0000 - RMSE: 523741.4688\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 249127534592.0000 - RMSE: 499126.7812\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 260432936960.0000 - RMSE: 510326.3125\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 295445069824.0000 - RMSE: 543548.5625\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 266916151296.0000 - RMSE: 516639.2812\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 533490466816.0000 - RMSE: 730404.3125\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 292131471360.0000 - RMSE: 540491.8750\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 267762286592.0000 - RMSE: 517457.5312\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 269256589312.0000 - RMSE: 518899.4062\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 270601338880.0000 - RMSE: 520193.5625\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 245808840704.0000 - RMSE: 495791.1250\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 229581930496.0000 - RMSE: 479147.0938\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 240604905472.0000 - RMSE: 490514.9375\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 263758594048.0000 - RMSE: 513574.3438\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 240809705472.0000 - RMSE: 490723.6562\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 231686864896.0000 - RMSE: 481338.6250\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 214247391232.0000 - RMSE: 462868.6562\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 309219459072.0000 - RMSE: 556075.0625\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 261789581312.0000 - RMSE: 511653.7812\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 234778394624.0000 - RMSE: 484539.3750\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 221568253952.0000 - RMSE: 470710.3750\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 8s 31ms/step - loss: 221145300992.0000 - RMSE: 470260.8750\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 202282401792.0000 - RMSE: 449758.1562\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 8s 30ms/step - loss: 207109324800.0000 - RMSE: 455092.6562\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 203576918016.0000 - RMSE: 451195.0000\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 211635535872.0000 - RMSE: 460038.6250\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 7s 30ms/step - loss: 201234890752.0000 - RMSE: 448592.1250\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 190725029888.0000 - RMSE: 436720.7812\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 202418438144.0000 - RMSE: 449909.3750\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 225398996992.0000 - RMSE: 474762.0312\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 206308655104.0000 - RMSE: 454212.1250\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 199909638144.0000 - RMSE: 447112.5625\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 183402283008.0000 - RMSE: 428254.9375\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 7s 29ms/step - loss: 199977172992.0000 - RMSE: 447188.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe8415c9e8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = split_sequences(df.drop([\"estados\", \"data\"], axis=1).values, 7)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)\n",
    "scaler = StandardScaler3DShape()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = get_model()\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "TRAIN\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 423433.78527969075\n",
      "MAE: 250094.0660791855\n",
      "MAPE: 0.3648506572458502\n",
      "================\n",
      "TESTE\n",
      "================\n",
      "Scores obtidos:\n",
      "RMSE: 1540075.196064732\n",
      "MAE: 748130.5561810052\n",
      "MAPE: 1.4345033264539517\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(\"TRAIN\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_train)\n",
    "scores = score_regression_metrics(y_train, y_pred)\n",
    "show_scores(scores)\n",
    "\n",
    "print(\"================\")\n",
    "print(\"TESTE\")\n",
    "print(\"================\")\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "scores = score_regression_metrics(y_test, y_pred)\n",
    "show_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
