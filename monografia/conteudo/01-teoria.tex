%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101

\chapter{Fundamentação teórica}

\section{Aprendizado de máquina}

Atualmente, inteligência artificial (IA) permeia diversos 
momentos do cotidiano. É o caso da empresa norte-americana 
de \textit{streaming} Netflix, que utiliza um conjunto de 
técnicas de IA para recomendar conteúdo personalizado aos 
usuários da plataforma de acordo com os interesses 
particulares de cada um. Dessa forma, proporciona uma 
experiência única a cada indivíduo que acessa a plataforma 
com o objetivo de aumentar a satisfação a longo prazo e, 
consequentemente, garantir a retenção dos membros, uma vez 
que a plataforma é monetizada com assinaturas mensais. 

Além disso, não há um modelo ou algoritmo único utilizado 
para todas as recomendações de conteúdo. Essa tarefa é 
dividida em subtarefas realizadas por diferentes modelos de 
acordo com a atividade a ser realizada e os dados disponíveis. 
Por exemplo, a subtarefa de  decidir qual vídeo será exibido para 
cada usuário ao logar no perfil da plataforma é executada por um 
modelo diferente do que o que elenca os vídeos já assistidos que o 
membro pode continuar a ver. \cite{netflix}

Mas a final, o que é inteligência artificial (IA)? O termo 
"inteligência artificial", \textit{artificial intelligence} 
em inglês, foi elaborado por John McCarthy e utilizado 
oficialmente pela primeira vez em 1956 no seminário de 
Dartmouth, um \textit{workshop} sobre essa área que reuniu os 
maiores estudiosos do ramo durante dois meses. \cite{aima} 
Esse termo apresenta várias definições, de acordo com o 
pioneiro Arthur Samuel, pode ser definida como o campo de 
estudo que dá aos computadores a habilidade de aprender sem 
serem explicitamente programados. \cite{dl-oreilly} 

Aprendizado de máquina, por sua vez, do inglês 
\textit{machine learning}, são sistemas de IA capazes 
de adquirir seu próprio conhecimento por meio da extração 
de padrões dos dados brutos. Configura-se, portanto, como 
uma sub-área de inteligência artificial.
\cite{Goodfellow-et-al-2016}. O aprendizado profundo, ou 
\textit{deep learning}, é uma categoria específica de
 \textit{machine learning} que compreende modelos de redes 
 neurais com várias camadas de neurônios.\cite{d2l}

\begin{figure}[H] 
  \includegraphics[width= 10cm]{../figuras/ia_ml.png}
  \label{fig:ia_ml}
  \caption{Relação entre inteligência artificial, aprendizado de máquina e \textit{deep learning} \cite{dl-oreilly}}
\end{figure}

\section{Problema}

As tarefas de \textit{machine learning} são descritas de acordo com o processamento 
que o modelo deve realizar a partir de um exemplo de entrada (\textit{input}), em geral, descrito com 
um vetor $x \in \mathbb{R}^n, x=\{x_1, x_2, ..., x_n\}$. Por exemplo, neste trabalho um 
exemplo de \textit{input} seriam os dados 
de março de 2011 do estado de São Paulo, cada entrada $x_i$, então, corresponde à medição 
de um dos indicadores econômicos desse estado e mês, logo $x_1$ pode representar
o PIB estadual, $x_2$ o PIB \textit{per capita} e assim sucessivamente. 

Nas tarefas de classificação, o modelo deve prever a qual das $k$ categorias 
disponíveis um \textit{input} pertence. O algoritmo então cria uma função  
$ f : \mathbb{R}^n \rightarrow {1,...,k}$,  quando 
$ f(x) = y$, o vetor de entrada $x$ foi recebeu a categoria $y$. Um exemplo 
de tarefa de classificação seria determinar se o consumo de cimento em um estado em um mês específico 
representa um aumento, queda ou estabilidade em relação ao mês anterior. 
Neste trabalho, contudo, não se utiliza esse tipo de tarefa.\cite{Goodfellow-et-al-2016}

Outra categoria de tarefas são as de regressão, aonde o objetivo é, a partir do \textit{input x}, 
prever um valor numérico. A função criada pelo modelo, então, é $ f : \mathbb{R}^n \rightarrow \mathbb{R}$. 
O problema abordado neste trabalho, então, configura-se como problema de regressão, uma vez que o objetivo 
é prever o valor do consumo de cimento em um estado e mês específicos a partir dos dados de entrada.

Os problemas de aprendizado de máquina também podem ser divididos entre
 aprendizado não-supervisionado e supervisionado. No primeiro, o modelo recebe
um \textit{dataset} não rotulado e então aprende propriedades da estrutura do \textit{dataset}, pode, então
performar tarefas como a clusterização, que consiste em dividir o conjunto de dados
em \textit{clusters} com exemplos similares. No último, por sua vez, os dados de 
entrada estão associados a rótulos, resultados conhecidos, chamados de \textit{labels} ou
\textit{target} em inglês. Neste trabalho, a utiliza-se aprendizado supervisionado, uma vez 
que o real consumo de cimento no mês é conhecido.\cite{Goodfellow-et-al-2016}

  
\section{Regressão linear}
\label{sec:reg_lin}

A regressão linear é um modelo de aprendizado de máquina que assume um relacionamento
linear entre a variável que será prevista (\textit{target}) e os dados de entrada.
Dessa forma, o objetivo é obter uma função linear que receba um vetor 
$x \in \mathbb{R}^n , x=\{x_1, x_2, ..., x_n\}$
como entrada e devolva a previsão de um escalar $y \in \mathbb{R}$. \cite{Goodfellow-et-al-2016}
Seja $\hat{y}$ o valor previsto pelo modelo para $\hat{y}$, então:

\begin{equation}
  \label{eq:reg_lin}
  \hat{y} = w^T x + b
\end{equation}

aonde $ w \in \mathbb{R}^n, w=\{w_1, w_2, ..., w_n\}$ é um vetor de parâmetros. Em 
particular, $w$ corresponde a um conjunto de pesos que 
determina como cada variável afeta a previsão. Então, se $x_i$
for associado a um peso $w_i$ positivo, aumentar o valor de $x_i$
resulta em um aumento na previsão $\hat{y}$, se $w_i$ for negativo, 
por outro lado, um aumento de $x_i$ resulta em diminuição de 
$\hat{y}$. Se $w_i$ for igual a 0, por sua vez, a 
variável $x_i$ não influencia no valor previsto.

A constante $b$, do inglês \textit{bias}, é um parâmetro para
mensurar viés, já que o \textit{output} da função é $b$ na ausência
de uma entrada. Dessa forma, a equação \ref{eq:reg_lin} pode ser escrita da 
seguinte forma: 

\begin{equation}
  \hat{y} = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b
\end{equation}

Na ilustração abaixo, um exemplo de um modelo de regressão 
linear com apenas uma variável:

\begin{figure}[H] 
  \includegraphics[width= 10cm]{../figuras/reg_lin.png}
  \caption{Exemplo de um modelo simples de regressão linear
  \cite{forecasting}}
  \label{fig:reg_lin}
\end{figure}

Nessa imagem, as observações estão 
representadas nos pontos pretos, enquanto a linha em laranja
corresponde à previsão realizada pelo modelo. Observa-se que
o modelo não prevê com total exatidão os dados observados, há 
um erro associado a cada previsão, como o destacado em verde 
na ilustração.

Dessa forma, cada observação $y_i$ possui um erro ${\varepsilon}_i$ 
associado e pode ser descrita por $y_i = w^T x_i + b + {\varepsilon}_i$.
O vetor de pesos $w$, então, é escolhido de modo a minimizar 
os erros em cada previsão.

Por se tratar de um modelo mais simples, é utilizada neste trabalho como base 
para comparar o desempenho de outros modelos mais robustos.

\section{Redes neurais}

Redes neurais são modelos computacionais inspirados no funcionamento
do cérebro animal, onde neurônios trabalham em paralelo sem 
uma unidade central de controle. Um neurônio biológico é uma célula 
nervosa que se comunica com outros neurônios e passa impulsos 
eletro-químicos de uma célula para outra por meio das sinapses.
A comunicação entre neurônios, sinapse, ocorre apenas se o impulso 
for forte o bastante para ativar a liberação de
químicos na fenda sináptica.

Um neurônio é composto de vários dendritos, um axônio e corpo 
celular, como na imagem \ref{fig:neuron}. 

\begin{figure}[H] 
  \includegraphics[width= 12cm]{../figuras/neuron.png}
  \caption{Ilustração de um neurônio biológico. \cite{dl-oreilly}
  Destaca-se a informação chegando a um dendrito do neurônio
  por meio de uma sinapse, além de uma sinapse que se inicia no axônio 
  do neurônio e propaga informação a diante.
  }
  \label{fig:neuron}
\end{figure}

Os dendritos recebem 
informações de outros neurônios vizionhos, na forma de impulsos
elétricos, e conduzi-las até o corpo celular. Ao chegar no corpo
celular, a informação é processada e novos impulsos são gerados. 
Essa informação é, então, repassada para outro neurônio 
através do axônio por meio de sinapse. Dessa forma, sinapse é o
ponto de contato entre a terminação axônica de um neurônio e o 
dendrito de outro.\cite{deeplearningbook}. 

A estrutura e funcionamento dos neurônios biológicos foram 
base para os cientistas criarem neurônios artificiais, como 
os \textit{perceptrons}. 

\subsection{Neurônios artificiais}

O \textit{perceptron}, foi desenvolvido em 1957 por Frank 
Rosenblatt, inspirado nos trabalhos de Warren McCulloch e Walter Pitts.
Trata-se de um modelo linear de classificação binária que 
recebe $n$ entradas e produz uma saída binária, como mostrado 
na ilustração simplificada \ref{fig:perceptron-simples}.\cite{deeplearningbook}
Esse modelo inicial apresentava limitações e foi evoluído com o passar do 
tempo, as redes neurais atualmente, em geral, utilizam 
outro modelo de neurônio como ilustrado em \ref{fig:perceptron}.


\begin{figure}[H] 
  \centering
  \begin{subfigure}{7cm}
    \centering 
    \includegraphics[width=7cm]{../figuras/perceptron-simples.png}
    \caption{Visão simplificada de um neurônio \cite{deeplearningbook}}
    \label{fig:perceptron-simples}
  \end{subfigure}
  \hfill
  \begin{subfigure}{7cm}
    \centering
    \includegraphics[width=7cm]{../figuras/perceptron.png}
    \caption{Ilustração da arquitetura de um 
    neurônio artificial \cite{dl-oreilly}}
    \label{fig:perceptron}
  \end{subfigure}
\end{figure}

Como é possível observar na figura \ref{fig:perceptron}, cada
uma das entradas $x_i$ está associada a um peso $w_i$. Os pesos
$w_1, w_2, ..., w_n$ expressam a importância das respectivas
entradas para o valor de saída, de modo semelhante à 
regressão linear na seção \ref{sec:reg_lin}. O produto escalar entre
os pesos e as respectivas entradas, chamada de \textit{net input}
na imagem \ref{fig:perceptron}, passa por uma função de 
ativação $\phi$ que determina a saída do neurônio. 
Além disso, um valor de \textit{bias} ou polarização é
adicionado ao produto escalar para aumentar a liberdade 
da função. O \textit{bias} possibilita que 
um neurônio que possua todas as entradas nulas a 
apresente saída não nula, dessa forma,
aumenta a capacidade de aproximação da rede. 
\cite{deeplearningbook}


Seja $x$ o vetor das $n$ entradas do neurônio, então
$x \in \mathbb{R}^n, x=\{x_1, x_2, ..., x_n\}$, seja também 
$w$ o vetor com os pesos associados a cada entrada, 
$w \in \mathbb{R}^n, w=\{w_1, w_2, ..., w_n\}$. Além disso,
seja $b$ o valor de \textit{bias} e $\Phi$ a função de ativação.
Dessa forma, o \textit{output} de um neurônio é dado por:
 
\begin{equation}
  h_{w,b} = \Phi(w \cdot x + b)
\end{equation}

Essa saída é utilizada como uma das entradas dos neurônios
na camada seguinte, de modo a formar a estrutura das redes 
neurais semelhante ao funcionamento do cérebro. Os neurônios,
então, formam a unidade que compõe as redes neurais artificiais,
como ilustrado na figura abaixo:

\begin{figure}[H] 
  \includegraphics[width= 12cm]{../figuras/rede-neural.png}
  \caption{Ilustração de uma rede neural simples.\cite{deeplearningbook}}
  \label{fig:redeneural}
\end{figure}


\subsection{Função de ativação}

A função de ativação propaga a saída de um 
neurônio na rede neural para a camada seguinte. Enquanto os pesos 
e o \textit{bias} realizam uma transformação linear nos dados 
de entrada, a função de ativação aplica uma transformação não
linear e dessa forma torna possível que a rede neural resolva
problemas não lineares e complexos, como reconhecer padrões de 
escrita.\cite{deeplearningbook}

A função de ativação é um atributo de cada uma das camadas 
da rede e é escolhida de acordo com a tarefa que será 
executada, por exemplo, a função sigmóide é recomendada
 para problemas de classificação. Neste trabalho, 
foram utilizada: \textit{rectified linear unit} (ReLU) e \textit{swish}.

\subsubsection{Rectified linear unit (ReLU)}

A função ReLU, do inglês \textit{rectified linear unit}, é o 
estado da arte atualmente, uma vez que apresenta bom desempenho 
em diferentes tarefas. \cite{dl-oreilly} A função ReLu é dada por:

\begin{equation}
  f(x) = max(0,x)
\end{equation}

Ao utilizar essa função, a derivada, utilizada para atualizar
os pesos e \textit{bias} no treinamento da rede, é zero, quando 
a entrada é nula ou uma constante, como na imagem abaixo. Dessa
forma, a ReLU não sofre do problema da dissipação do gradiente como
a sigmóide.

\begin{figure}[H] 
  \includegraphics[width= 8cm]{../figuras/relu.png}
  \caption{Rectified linear unit (ReLU) \cite{dl-oreilly}}
  \label{fig:relu}
\end{figure}

\subsubsection{Swish}

A função \textit{swish} foi proposta por pesquisadores da 
Google com a prerrogativa de apresentar melhor desempenho 
que a ReLU em redes neurais profundas. \cite{swish}

A \textit{swish} é uma função não monotônica e suave 
dada por:

\begin{equation}
  f(x) = x \cdot sigmoid(x) = \frac{x}{1+e^{-x}}
\end{equation}


O gráfico da função é similar ao da ReLU:

\begin{figure}[H] 
  \includegraphics[width= 8cm]{../figuras/swish.png}
  \caption{Função \textit{swish} \cite{swish}}
  \label{fig:swish}
\end{figure}

\subsection{Redes neurais multi-layer perceptrons}
  % dar uma melhorada -> parte do com o treinamento fornecido
  % se agredar -> combinação -> melhorar
  % redes de arquitetura multilayer ...
  % o "e feedforward" não tem nada a ver -> é um passo do treinamento  -> sequencia dos dados de entrada
Redes neurais são modelos de \textit{machine learning} 
inspiradas no cérebro humano aonde o aprendizado ocorre 
ao se agregarem neurônios matemáticos que 
estabelecem conexões de acordo com o treinamento fornecido. 
Neste trabalho, aplicaram-se redes 
\textit{multilayer perceptrons} (MLPs), ou seja, que 
apresentam múltiplas camadas de neurônios 
e \textit{feedfoward}, onde a saída de 
uma camada de neurônios é utilizada como entrada para a camada seguinte, sem utilizar retropropagação.
          
        
\subsection{Redes Neurais Recorrentes}
\label{rnn}
Já as redes neurais recorrentes são projetadas para reconhecer padrões nos dados, uma vez que levam tempo e sequência em consideração. Assim, nessas redes, a decisão tomada na etapa anterior influencia a etapa seguinte por conta dos \textit{loops de feedback}, então o presente e o passado recente se combinam para determinar a previsão. Neste trabalho, foram testadas as redes Long Short Term Memory (LSTM), redes Gated Recurrent Unit (GRU) e Bidirecionais.
  
\subsubsection{GRU}

\subsubsection{LSTM}

\subsection{Normalização}